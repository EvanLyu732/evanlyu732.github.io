<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>


    
        <link rel="alternate" type="application/rss+xml" title="RSS" href="https://evanlyu732.github.io/atom.xml">
    
    
    
        
    
    
    
    
    
    
        
    
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>evan lyu</title>
    <meta charset="utf-8">
    <meta name="title" content="evan lyu">
    <meta name="description" content="">
    <meta property="og:image:width" content="200" />
    <meta property="og:image:height" content="200" />
    <link rel="stylesheet" href="https:&#x2F;&#x2F;evanlyu732.github.io/style.css">
    
    
    <style>
    @media screen and (min-width: 320px) {
        body {
            font-size: calc(16px + 2 * ((100vw - 320px) / 960));
        }
    }
    </style>
    
    <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Source+Serif+Pro:wght@400;700&display=swap">
    <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:wght@400;700&display=swap">
    <style>body { font-family: 'Source Serif Pro', 'Source Han Serif SC', 'Noto Serif CJK SC', 'Noto Serif SC', serif }</style>
    
</head>
<body>
    
    <header class="header">
        <div class="blog-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io" class="logo">evan lyu</a></div>
        <nav class="navbar">
    <ul class="menu">
        
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;" class="current-menu-item-link">主页</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;archives" class="menu-item-link">归档</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;about" class="menu-item-link">关于</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;note" class="menu-item-link">书架</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;atom.xml" class="menu-item-link">订阅</a>
            
        </li>
        
    </ul>
</nav>

    </header>
    
    <main class="main">
        
<section class="posts">
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog8&#x2F;" class="post-title-link">LLM OS的曙光</a></div>
        <div class="post-content">
            
                <p>在今天的OpenAI的春季发布会, OpenAI发布了<a href="https://openai.com/index/hello-gpt-4o/">gpt-4o</a>. 虽然前几代模型也支持语音功能, 但是在gpt-4o中, 其中任意打断的能力和更快的响应速度, 实在是难以让人区分出是机器人还是人类. 但是现在每次对话都需要重新用语音prompt, 来让模型产生预期的“性格”. 所以显而易见的, 不久后的GPT商店会上架不同“性格”的AI. 以及对自定义AI的支持.</p>
<p>语音和图像的联动是另一项gpt-4o所突出展示出的能力. 用语音交互的方式来让AI分析实时的摄像头数据. 并且在pc端通过桌面端应用还具备<a href="https://www.youtube.com/watch?v=ZJbu3NEPJN0">voice copliot</a>的能力. 已经能让生产力提高到下一个层次. 很明显在未来能够 <u>清晰的表达想法和理解问题</u> 的能力比单纯的技能更加重要. 其实这已经是LLM OS的一个很大的突破了.</p>
<p>随着OpenAI开放更加便宜的AI, OpenAI的影响力肯定会进一步扩大. 他们所能获取的数据集肯定越来越多. 假如世界模型是一个向量f(x), 根据<a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">Universal approximation theorem</a>. 因此世界模型会被拟合, 假如未来的模型架构迭代, 比如使用<a href="https://arxiv.org/pdf/2404.19756">Kolmogorov–Arnold Networks</a>. 实际上变的也是拟合的基函数, 核心思想都是一致. 也是对世界模型的拟合. 因此, AI最终一定会解决现有的世界模型 f(x) 的一切问题. 但是以这种方式的AI不具备创造力.</p>
<p>如何让AI具备创造力? 这篇文章<a href="https://arxiv.org/pdf/2002.06177">The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence</a>的作者就很好的分析了这个问题. <a href="https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/">现有的AI始终受限于数据集</a>. AGI需要有对知识的归纳和演化的能力.以下是原文链接.</p>
<blockquote>
<p>a reasoning system that can leverage large-scale background knowledge efficiently, even when available information is incomplete is a prerequisite to robustness. - p40</p>
</blockquote>
<p>因此在未来的AGI形态，会有一个底座的知识语料, 在这个底座的知识语料当中, AI有知识关联, 归纳, 推理能力. 当AI不断的从世界模型提炼信息的时候, 也会对这个底层的知识语料进行加工. 类比于人类来说的话, 人在不断接触外部信息源的时候也会不断迭代自己的世界观(或者说每个人的人生哲学). 而当人遇到未接触的问题时, 在没有外部信息源的接触下, 也会依赖于自己的世界观进行加工和理解.</p>
<p>或许未来出现一种形态, 在神经网络(知识的拟合)里面嵌套专家系统(知识的推理). 能够让AI真正具有创造力.</p>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年五月十四日

            
        </div>
    </article>
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog7&#x2F;" class="post-title-link">2024百度Create ai大会</a></div>
        <div class="post-content">
            
                <h1 id="can-hui-ji-lu">参会记录</h1>
<p>记录一下本周线下参加的2024百度Create ai大会, 大会回放链接点击<a href="https://create.baidu.com/?lng=en">这里</a>. 大会的主要内容是百度的ai产品发布会. 我当时看大部分演讲的内容其实更多的是偏应用方面. 我个人对技术方面的内容更感兴趣就只参加了主论坛并且只听了前三场讲座.</p>
<p><img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/baidu-create00.jpg" alt="intro" /></p>
<p>首先开场的是李彦宏, 他讲的大部分内容都是偏向产品端. 我印象比较深刻的是开场没多久就说了下面这张图. &quot;未来大型的AI原生应用基本都是MOE.&quot; .并且他说明这里的MOE指的是混合模型(Mixture Of Engine)并不是技术上的MOE, 出于对技术上指代的MOE的好奇, 我开始去研究Mixture Of Experts. <a href="https://twitter.com/karpathy/status/1723140519554105733?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1723140519554105733%7Ctwgr%5E07d2037d9d6cbc882a44890ce223b50c270f617e%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2Fkarpathy%2Fstatus%2F17231405195541057333Fs3D4626t3DuuEcj3Up_XwhDshmNCpLBQimage%3Dhttps3A%2F%2Fabs.twimg.com%2Ferrors%2Flogo46x38.png">这个链接 </a>是非常好的资料. 现有很多大模型会包含Mixture Of Experts Layer. 因此在提示词工程里面需要有角色扮演, 相当于激活特定分支的Expert来让优化输出结果.</p>
<p><img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/baidu-create01.png" alt="moe" /></p>
<p>之后是王海峰介绍的多模型推理部分. 也是从输入端会经过路由模型. 再由路由模型分发输入给不同的模型. 实际上所谓的Mixture Of Engine与Mixture Of Experts的思想是一致的. 只不过是宏观(多个模型)与微观(单个模型)之间的区别.
<img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/baidu-create02.png" alt="infer" /></p>
<p>最后是沈抖介绍的万源智能操作系统, 与Andrej Karpathy所提及的<a href="https://twitter.com/karpathy/status/1723140519554105733?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1723140519554105733%7Ctwgr%5E07d2037d9d6cbc882a44890ce223b50c270f617e%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2Fkarpathy%2Fstatus%2F17231405195541057333Fs3D4626t3DuuEcj3Up_XwhDshmNCpLBQimage%3Dhttps3A%2F%2Fabs.twimg.com%2Ferrors%2Flogo46x38.png">LLM-OS</a>是相同的. 之前看过Andrej的一个talk里面就讲到基本所有人都在往LLM-OS发力. 将一个复杂任务拆解的话, 现有的LLM已经具有相当的理解能力, 但是缺少对工具的使用能力. 如果要让LLM能够使用工具的话, 许多现有的应用都要重新开发. 或许也是未来的一个风口所在.</p>
<p><img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/baidu-create06.png" alt="wanyuan" /></p>
<h1 id="can-kao-zi-liao">参考资料</h1>
<p>下面是对于了解Mixutre Of Experts有帮助的链接:</p>
<ul>
<li>https://developer.nvidia.com/blog/applying-mixture-of-experts-in-llm-architectures/ </li>
<li>https://stackoverflow.blog/2024/04/04/how-do-mixture-of-experts-layers-affect-transformer-models/</li>
<li>https://developer.nvidia.com/blog/mastering-llm-techniques-training/</li>
</ul>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年四月十七日

            
        </div>
    </article>
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog6&#x2F;" class="post-title-link">工具的重要性</a></div>
        <div class="post-content">
            
                <h1 id="bei-jing">背景</h1>
<p>最近在思考关于&quot;技术无用论&quot;的说法. 从事程序工作难免会遇到技术无用论的观点. 持有这样观点的人通常的思路如下:
比方说, 在一个公司里往往靠的是商务能力生存下去, 而技术往往是服务于商务. 而商务的变更就会直接影响到一个项目是否要推进下去.
直白点, 技术是商务的下游. 而上游决定下游, 如果上游不存在自然下游也不存在, 并且技术只是实现目的的一种手段, 而不是唯一. 因此技术不重要.</p>
<p>与其相似的是第二个观点是“工具无用论&quot;. 举个具体的例子, 很多人会认为学习vim或者emacs这种编辑器是浪费时间, 付出对应的学习成本是没有必要的. 或者折腾arch linux，window manager这些也是花里胡哨, 没什么实际用处. 类似的, 编程语言学习一两种就行了, 语言只是工具, 都差不多, 学会了一种再学其他的语言也很快. 毕竟还是需要面向“薪资”编程.</p>
<h1 id="zheng-wen">正文</h1>
<p>要给出结论需要一些铺垫. 我相信提出上面观点的人不会怀疑“薪资”或者财富是无用的. 所有的人都想解决“财富”问题. 这里要明确一点就是. <strong>财富不等于金钱，财富是金钱的载体</strong>. 如果社会流通金钱远远超过了载体的数量就会导致通货膨胀, 或者在某个具体的行业产生泡沫, 追求金钱是追求财富的副产物, 而财富还有其他名字, 它也叫做产品或者服务. 而通常意义上来讲, 工作就是指创造产品或者提供服务的时间. 提供产品可以不用金钱, 最好的例子某过于开源或者免费服务. 一个组织或者个人所提供的产品的影响力越大, 相应的, 组织也会获得越多的金钱. 组织中的个人也会获得更好的薪资待遇. 因此，<strong>金钱直接与影响力</strong> 挂钩. <a href="https://www.amazon.com/Millionaire-Fastlane-Crack-Wealth-Lifetime/dp/0984358102">The Millionaire Fastlane: Crack the Code to Wealth and Live Rich for a Lifetime</a>中有一个公式很清晰的表达了这个过程:</p>
<blockquote>
<p>Wealth = Width * Depth</p>
</blockquote>
<p>这里的Wealth我更倾向于解读成金钱. 金钱的数量取决于产品的影响力的广度(受众的个数)乘深度(用户粘性).  在这个过程中, 去提供对应的产品需要对应的工具, 程序员需要编程语言去创造软件, 雕塑家需要对应的工具去创建雕塑. 任何行业的专业人员都需要专业的工具的提供相应的产品.</p>
<p><strong>那技术在这个链路里面指的是什么呢？</strong> </p>
<p>在中文语境下, 技术往往有两个指向:</p>
<ol>
<li>技术指代的是工具本身, 即技术等于工具</li>
<li>技术指代的是创造工具的背景或者说基础知识</li>
</ol>
<p>由于技术这个词同时有两个指代, 我认为有不同观点是第二个指代. 第一种指代是创造产品必需的, 好的技术能更好服务于产品. 从而创造更大的影响力. 而第二种指向对于使用工具的人来说很重要, 但对于创造产品没有直接影响. 从这个角度上讲, 第二种指向的技术确实没什么用. 所以我在这里想反驳的其实是第二种观点, 即“工具无用论”. 更具体的说是在软件开发工程中, 好的工具是如何改变思维的.</p>
<h1 id="lun-gong-ju-de-zhong-yao-xing">论工具的重要性</h1>
<p>截止到2024年还无法完全使用AI相关的工具达到全流程闭环的今天, 我认为软件开发可以用一句话总结:&quot;通过某种交互方式进行文本编辑, 按照规则(编程语言), 实现模型的过程称为软件开发&quot;. 所以这里面有三个因素:</p>
<ul>
<li>文本编辑</li>
<li>规则(编程语言)</li>
<li>模型</li>
</ul>
<p>模型会根据不同行业而有所区分, 因此不具有通用性. 由于99.99%的人都无法创造 <strong>有生态以及有社区影响力的规则</strong> , 因此都必须要理解规则, 按照规则进行开发. 而不管进行哪种软件开发, 都需要进行文本编辑. 熟练使用Vim以及Emacs都可以让编辑速度有质的提升, 加速了迭代速度, 从而让更多的开发时间花在模型的构建上. 同时能够熟练掌握Vim以及Emacs能够更好的帮助你理解规则. 但是Vim和Emacs的定位不一样, Vim更强调的是编辑本身, Vim配置也更多的是编辑本身的拓展, 而在Emacs里面任何操作都是一条命令, 通过Elisp去自定义命令达到预期的功能. 这里十分推荐Hacker news上的一篇<a href="https://news.ycombinator.com/item?id=30709487">Post</a>, 然而在工作中真正花时间能够很熟练使用Vim的人已经寥寥无几, 使用Emacs的就更稀有了. 并不是每个学校都像mit会开<a href="https://missing.csail.mit.edu/">The Missing Semester of Your CS Education</a>这种课. 这也是国内大部分高校计算机教育缺少的一环, 我认为在大学里面花一个学期把Vim或者Emacs当成主修一点都不为过. 它们能够直接加深对计算机的理解.</p>
<h1 id="lispyu-qi-ta-yu-yan">Lisp与其他语言</h1>
<p>不是专门研究编程语言或者折腾Emacs的话, 大部分人应该都不会接触Lisp相关的语言. 但Lisp实在是太独特了, 学习Lisp可以影响思维. 由于Lisp的dialect(方言)很多, 有lexical scoping, 而有dynamic scoping的. 但是精华部分都有一致性, 在Lisp中任何函数调用最终都是由eval去执行, 任何数据都是Data, 函数是Data. 并且几乎没有语法. 只有一种数据结构就是list, 而list只有两个部分构成, car和cdr. 通过操作car(contents of address part of a register)，cdr(contents of the decrement part of a register). Lisp就像<a href="https://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567">GEB</a>里面说的strange loop的完备符号形式, 一旦了解了lisp的基本结构, 会发现没有任何语言能像它一样简洁. 如果让我重新学习编程, 我肯定会先选择这本1990年出版的<a href="https://www.cs.cmu.edu/~dst/LispBook/book.pdf">Common Lisp</a>书籍作为学习编程的第一本教材.</p>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年三月十日

            
        </div>
    </article>
    

</section>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

    <script>
        var Home = location.href,
        xhr,
        xhrUrl = '';
    
        var Diaspora = {
            L: function(url, f, err) {
                if (url == xhrUrl) {
                    return false;
                }
                xhrUrl = url;
                if (xhr) {
                    xhr.abort();
                }
                xhr = $.ajax({
                    type: 'GET',
                    url: url,
                    timeout: 10000,
                    success: function(data) {
                        f(data);
                        xhrUrl = '';
                    },
                    error: function(a, b, c) {
                        if (b == 'abort') {
                            err && err()
                        } else {
                            window.location.href = url;
                        }
                        xhrUrl = '';
                    }
                });
            },
            loading: function() {
                var w = window.innerWidth;
                var css = '<style class="loaderstyle" id="loaderstyle'+ w +'">'+
                    '@-moz-keyframes loader'+ w +'{100%{background-position:'+ w +'px 0}}'+
                    '@-webkit-keyframes loader'+ w +'{100%{background-position:'+ w +'px 0}}'+
                    '.loader'+ w +'{-webkit-animation:loader'+ w +' 3s linear infinite;-moz-animation:loader'+ w +' 3s linear infinite;}'+
                    '</style>';
                $('.loaderstyle').remove()
                $('head').append(css)
                $('#loader').removeClass().addClass('loader'+ w).show()
            },
            loaded: function() {
                $('#loader').removeClass().hide()
            }
        };
    
        $(function() {
            $('body').on('click', function(e) {
                var tag = $(e.target).attr('class') || '',
                    rel = $(e.target).attr('rel') || '';
                if (!tag && !rel) return;
                switch (true) {
                    // next page
                    case (tag.indexOf('more') != -1):
                        tag = $('.more');
                        if (tag.data('status') == 'loading') {
                            return false
                        }
                        var num = parseInt(tag.data('page')) || 1;
                        if (num == 1) {
                            tag.data('page', 1)
                        }
                        tag.html("旧文").data('status', 'loading')
                        Diaspora.loading()
                        Diaspora.L(tag.attr('href'), function(data) {
                            tag.hide();
                            $('.license').hide();
                            var link = $(data).find('.more').attr('href');
                            if (link) {
                                tag.attr('href', link).html("旧文").data('status', 'loaded')
                                tag.data('page', parseInt(tag.data('page')) + 1)
                            }

                            var tempScrollTop = $(window).scrollTop();
                            $('body').append($(data).find('.posts'))
                            $(window).scrollTop(tempScrollTop + 100);
                            Diaspora.loaded()
                            //$('html,body').animate({ scrollTop: tempScrollTop + 400 }, 500);
                            if (link !== '/' && link != '') {
                                $('body').append($(data).find('.page-nav'))
                            }
                        }, function() {
                            tag.html("旧文").data('status', 'loaded')
                        })
                        return false;
                        break;
                    default:
                        return true;
                        break;
                }
            });
        })
    </script>
    
    <nav class="page-nav">
      <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;page&#x2F;9&#x2F;" class="more">旧文</a>
    </nav>


    </main>
    
    <p class="license"></p>
    
</body>
</html>
